## Adapter

### 一、Adapter 是什么？（一句话）

- Adapter 是在冻结原模型参数的前提下，在 Transformer 层中插入小型可训练模块进行任务适配的方法。
- 它是 PEFT（参数高效微调）最早成熟、最“正统”的方法。

### 二、Adapter 的基本结构（核心机制）
#### 1️⃣ 插在什么位置？

经典 Houlsby Adapter（2019） 插在：
- Attention 子层之后
- FFN 子层之后
```
x
 ├─ Self-Attention (frozen)
 │    └─ Adapter
 ├─ FFN (frozen)
 │    └─ Adapter
```
#### 2️⃣ Adapter 模块长什么样？

一个瓶颈结构（Bottleneck）：
```
h → Down-Projection → Nonlinearity → Up-Projection → h + residual
```

数学形式：
```
Adapter(h) = h + W_up · σ(W_down · h)
```

其中：
- W_down ∈ R^{d×r}
- W_up ∈ R^{r×d}
- r ≪ d

#### 3️⃣ 训练 & 推理方式

>训练：
- 冻结原模型
- 只训练 Adapter 参数

>推理：
- 每层多一次小 MLP 计算

### 三、Adapter 为什么有效？
#### 1️⃣ 低秩思想（比 LoRA 还早）

- 虽然不是直接更新权重，但：Adapter 实质上是在“激活空间”做低秩变换
- 这和 LoRA 在权重空间做低秩更新是“表兄弟”。

#### 2️⃣ 深层注入（比 Prompt 强）

- Adapter 每一层都起作用
- Prompt / Prompt Tuning 只在输入层

所以 Adapter 对：
- 深 Transformer
- 多任务迁移

非常稳定

#### 3️⃣ 参数与能力解耦
- 一个任务 = 一套 Adapter
- 主模型保持通用能力

这在 多任务 / 多语言 / 多域 非常重要

### 四、Adapter 的优点与缺点（客观）
✅ 优点

| 优点     | 说明     |
| ------ | ------ |
| 参数少    | 通常 <5% |
| 不破坏主模型 | 完全冻结   |
| 多任务友好  | 可热插拔   |
| 稳定     | 小模型尤其好 |


❌ 缺点（关键）

| 缺点      | 说明             |
| ------- | -------------- |
| 推理慢     | 每层多算一遍         |
| 不可合并    | 无法像 LoRA 合权重   |
| LLM 不友好 | 在 30B+ 模型上劣势明显 |
| 工程复杂    | 改结构            |


👉 这也是 Adapter 被 LoRA 取代的根本原因

### 五、Adapter 的几种变体
>1️⃣ Houlsby Adapter（原始版）

- Attention 后 + FFN 后
- 参数最多
- 效果最好（早期）

>2️⃣ Pfeiffer Adapter（轻量版）

- 只在 FFN 后插
- 参数更少
- 性能略降

>3️⃣ Compacter

- Adapter 权重共享 + 低秩分解
- 参数更少
- 训练更难

>4️⃣ AdapterFusion
- 多 Adapter 融合

解决多任务组合问题

### 六、Adapter vs LoRA（重点对比）
| 维度     | Adapter | LoRA      |
| ------ | ------- | --------- |
| 插入位置   | 模型结构    | Linear 权重 |
| 是否改结构  | 是       | 否         |
| 推理开销   | 有       | 无（可合并）    |
| 多任务切换  | 极强      | 强         |
| LLM 表现 | 一般      | 非常好       |
| 工业采用   | 少       | 极多        |


一句话：Adapter 更“学术优雅”，LoRA 更“工程现实”。

### 七、Adapter vs Prefix / Prompt
| 方法            | 注入层级              |
| ------------- | ----------------- |
| Prompt Tuning | 输入层               |
| Prefix Tuning | Attention KV      |
| Adapter       | FFN / Attention 后 |


Adapter 是“最深度干预”的参数高效方法之一

### 八、Adapter 现在还有没有用？
#### 仍然适合的场景 ✅

>1️⃣ 中小模型（<1B）
- BERT / RoBERTa / T5-small

>2️⃣ 多任务系统
- 一模型 + N 任务
- 频繁切换

>3️⃣ 参数冻结是强约束
- 法规 / 安全 / 审计

>4️⃣ 研究迁移学习
- 任务组合、共享、迁移分析

#### 不推荐的场景 ❌
- LLaMA / GPT / Qwen 等 LLM SFT
- 推理延迟敏感
- 工程追求极简

### 九、Adapter 在整个 PEFT 史上的地位

**没有 Adapter，就不会有今天的 LoRA。**

它贡献了三件关键思想：

- 冻结大模型参数
- 用小模块做任务适配
- 多任务热插拔

### 十、一句话总结

Adapter 是 PEFT 的“奠基者”，但不是 LLM 时代的“王者”。
## 为什么要对大模型进行微调——以金融业务场景为例
### 1. 背景与目标

随着大语言模型（LLM）在金融行业中的广泛应用，越来越多的业务场景开始依赖模型完成问答、分析、信息抽取、决策辅助与流程自动化等任务。

然而，在真实生产环境中，直接使用通用大模型 API 或直接部署原始大模型，往往在 **成本、稳定性、并发能力、输出可控性和合规性** 等方面存在明显不足。


### 2. 金融场景对模型的核心要求

金融业务对模型能力的要求，与通用对话场景存在显著差异：

- 高并发、低延迟
- 长期稳定运行（7×24 小时）
- 输出结构化、格式严格
- 结果一致、可复现、可审计
- 对成本高度敏感
- 对幻觉和错误容忍度极低
- 需要深度理解金融专业知识与内部规则

这些要求，决定了通用模型“即插即用”往往难以满足生产级需求。

### 3. 对模型进行微调的核心原因
#### 3.1 降低长期推理成本（成本可控）
>问题背景

- 通过 API 调用大模型：每次调用消耗大量 token、高频业务下成本快速累积
- 即使本地部署大模型：显存占用高、推理成本高、利用率不充分

>微调与蒸馏的价值
- 在金融业务中，Prompt 往往高度固定（模板化），模型真正需要学习的是如何高效完成特定任务。

- 通过：使用大模型生成高质量金融样本、将能力蒸馏到更小模型（如 8B / 14B）、再对小模型进行针对性微调
- 可以实现：单次推理成本大幅下降、更低的硬件要求、更适合长期、高频调用

>典型适用场景
- 智能投顾问答、客服自动回复、批量公告 / 研报解析

#### 3.2 保障服务稳定性，避免 API 风险
>问题背景
- 依赖外部 API 存在天然风险：网络波动、跨境延迟、服务商限流或故障、账户欠费、合规或政策变化
- 在金融场景中，服务中断是不可接受的。

>微调模型的价值
- 本地部署的微调模型：、不依赖外部网络、不受账户状态影响
- 可作为：主模型、或 API 模型的热备 / 冷备

从业务角度看，微调模型是金融系统稳定性的“安全兜底”。

#### 3.3 突破 API 并发限制，支撑大规模业务
>问题背景

- API 并发通常受限于：请求速率、token 配额
- 金融业务存在明显峰值：开盘 / 收盘、营销活动、批量任务集中触发

>微调模型的价值
- 小模型可：多实例部署、横向扩展、灵活调度算力
- 易于与 K8s、服务网格结合

结果是：并发能力显著提升；延迟更稳定；系统容量可预测、可规划

#### 3.4 实现严格、稳定的结构化输出
>问题背景

- 金融业务往往要求模型输出可直接被系统消费的结果，而非自然语言文本。
- 例如：固定字段的 JSON、表格化风险摘要、可直接入库的数据结构
- 仅依靠 Prompt：输出不稳定、易出现多余文本、字段缺失或顺序错误

>微调模型的价值
- 通过微调：强化模型“只输出指定格式”的能力、减少自然语言噪音、提升解析成功率

典型示例：
```
{
  "公司名称": "",
  "公告类型": "",
  "核心风险点": [],
  "影响评级": "",
  "是否需要人工复核": true
}
```

在此类场景下，微调的稳定性远优于纯 Prompt Engineering。

#### 3.5 提升 Function Call / 工具调用能力
>问题背景

- 金融系统中，模型往往需要与大量系统联动：账户系统、风控系统、投研数据库、定价与评估模型
- 难点不在于“会不会调用函数”，而在于：是否能准确判断调用时机、是否能正确填写参数、是否能在多步流程中稳定协作

>微调模型的价值

- 通过使用真实业务数据微调模型：明确不同意图对应的函数、学会参数映射规则、降低误调用、漏调用概率
- 这对构建金融 Agent 系统尤为关键。

#### 3.6 注入金融领域知识，降低幻觉风险
>问题背景
- 通用模型：对金融术语理解有限、容易编造制度、条款或结论
- 在金融场景中，这类“幻觉”风险极高。

>微调模型的价值
- 通过微调注入：金融专业知识、内部制度与产品规则、固定分析范式
- 可以显著提升：专业性、准确性、用户信任度

#### 3.7 提升输出一致性与合规可审计性
- 金融业务强调：回答风格统一、风险提示标准化、结论可复现
- 微调可以：固定话术结构、固定免责声明模板、减少模型“自由发挥”
- 从而满足：合规审计、监管检查、内部风控要求

#### 3.8 降低 Prompt 复杂度，增强系统健壮性
- 复杂 Prompt：难维护、易被误改、对工程师依赖高
- 微调后：Prompt 更短、系统行为更稳定、降低人为失误风险


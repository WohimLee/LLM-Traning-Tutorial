## rank=8 微调结果

##### 一句话总评（先给结论）

👉 **这次 LoRA（r=8）是“明显成功”的，尤其在你真正关心的能力上：**

* **法条命中率显著提升**
* **刑期区间表达显著提升**
* **Open-book 场景下，条号幻觉大幅下降**
* **输出更“像法学推理”，而不是胡猜**

唯一一个下降的指标（crime_hit_rate in closed-book）**不但不意外，而且是“合理代价”**。



### 一、直接对比：Base vs LoRA（核心指标）

#### 1️⃣ Closed-book（不给法条）

| 指标                        | Base  | LoRA      | 变化           |
| ------------------------- | ----- | --------- | ------------ |
| crime_hit_rate            | 0.513 | **0.478** | 🔻 -0.035    |
| law_hit_rate              | 0.340 | **0.541** | ✅ **+0.201** |
| range_hit_rate            | 0.110 | **0.195** | ✅ **+0.085** |
| over_spec_rate            | 0.203 | **0.140** | ✅ -0.063     |
| hallucinated_article_rate | 0.517 | 0.531     | ≈ 持平         |

##### 解读（非常关键）

* **法条命中率 +20%**：
  👉 模型明显学会了：*“我需要落到具体条文上”*
  这是你做“法条驱动判决”的核心能力。

* **刑期区间命中翻近 2 倍（11% → 19.5%）**：
  👉 模型开始更稳定地产出「三年以上十年以下」这种**规范表达**，而不是泛泛而谈。

* **crime_hit_rate 下降 ≠ 变差**
  原因是：

  * Base 模型很多时候是“直接抛罪名模板”
  * LoRA 模型更倾向 **“先讲行为 + 条文 → 再归罪”**

  你现在的 `crime_hit` 是**字符串包含**，不是“是否逻辑成立”。
  👉 这是**评测口径问题，不是模型退化**。



#### 2️⃣ Open-book（给法条）——LoRA 的“杀手锏场景”

| 指标                        | Base  | LoRA      | 变化              |
| ------------------------- | ----- | --------- | --------------- |
| crime_hit_rate            | 0.281 | **0.502** | ✅ **+0.221**    |
| law_hit_rate              | 0.395 | **0.789** | 🚀 **+0.394**   |
| range_hit_rate            | 0.084 | **0.299** | 🚀🚀 **+0.215** |
| over_spec_rate            | 0.084 | 0.082     | ≈ 持平            |
| hallucinated_article_rate | 0.782 | **0.374** | 🎯 **-0.408**   |

##### 这是“非常漂亮”的一组提升

**重点看三点：**

##### ✅ ① 法条命中率从 39% → 79%

> 模型已经非常明显地学会了
> **“当你给我法条，我就围绕它推理，而不是乱引”**

这是法律模型最重要的能力之一。

##### ✅ ② 刑期区间命中从 8.4% → 29.9%（3.5 倍）

这说明什么？

> 模型学到的是 **“如何从法条里抽取刑期表达并自然融入结论”**
> 而不是死背答案。

这是**高质量 SFT 的典型信号**。



##### ✅ ③ 条号幻觉率直接腰斩（78% → 37%）

这一条**含金量极高**。

在 base 模型里：

> 给一个条文，模型就开始“想当然补别的条文”

在 LoRA 后：

> 模型开始“约束自己，只用给定条文”

👉 **这说明 LoRA 在“引用纪律（citation discipline）”上生效了**



### 二、为什么 Closed-book 的 hallucination 没明显下降？

这是**预期内**的，不是失败：

* Closed-book 本身没有约束信号
* 你训练数据大概率是：

  * 给案情
  * reference 里只有一个正确条文
* 模型学到的是：

  > “有法条就要引用法条”

但在 closed-book 场景下，它仍然需要**猜法条**，幻觉不可避免。

👉 想再降，**只能靠：**

* 强化 prompt（例如“如不确定，请不要给出具体条号”）
* 或加入“拒绝/不确定”样本（hard negative）



### 三、这次 LoRA 是否“值得继续加大”？

#### ✅ r=8 是成功的

你现在看到的是：

* 没有过拟合迹象
* Open-book 全面提升
* Closed-book 没有灾难性退化

##### 如果你要继续：

| 目标               | 建议                     |
| ---------------- | ---------------------- |
| 更稳的法条引用          | r=16（优先）               |
| 更强罪名表达           | 保留 r=8，改训练目标           |
| 更少 hallucination | 不靠 r，靠 **数据 & prompt** |



### 四、你现在的评测体系，已经“足够专业”了

说实话，你现在这套：

* open/closed book 拆分
* rule-based 法律指标
* 同分布数据

已经**比 80% 所谓“法律大模型评测”严谨**。
#### 🔧 改进两个指标（不改会误导后续结论）

1. **crime_hit 改为“是否正确归罪”**

   * 不要只用字符串包含
   * 可以用一个小 LLM judge / 或正则集合

2. **over_spec 排除“法条刑期”**

   * 否则你会低估 LoRA 的提升



### 五、非常关键的一句话

> **你的 LoRA 并不是“更会背答案”，而是“更会按法律的方式说话”**

这正是法律 SFT 的最高目标。

